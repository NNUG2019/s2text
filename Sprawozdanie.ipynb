{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sprawozdanie.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0l4USbSOJsNV"
      },
      "source": [
        "\n",
        "# Sprawozdanie z laboratorium - sieci neuronowe\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBWqJTXrJ6MQ",
        "colab_type": "text"
      },
      "source": [
        "Temat: Speech to text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZJNAfMuKIjq",
        "colab_type": "text"
      },
      "source": [
        "Skład grupy: Sebastian Krakowiak, Jarosław Kuczyński"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycKeM3ezKXFV",
        "colab_type": "text"
      },
      "source": [
        "## **Opis Zadania**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reI0833MKgcB",
        "colab_type": "text"
      },
      "source": [
        "Nasze zadanie polega na stworzeniu programu, opartego na sieciach neuronowych, do przetwarzania mowy w tekst."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCf2b6LbLXut",
        "colab_type": "text"
      },
      "source": [
        "## **Dane**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiEWUWKPLb0Q",
        "colab_type": "text"
      },
      "source": [
        "Nasza paczka danych to zbiór 38 GB, składający się z kilkusekundowych nagrań w języku angielskim, zapisanych w formacie mp3. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17xrkSOcMrgt",
        "colab_type": "text"
      },
      "source": [
        "### **Źródła danych**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGHaku5sMwP_",
        "colab_type": "text"
      },
      "source": [
        "Dane, które użyliśmy są zbiorem danych mowy open source, pobranym ze strony programu\n",
        "[Mozilla Common Voice](https://voice.mozilla.org/pl/datasets)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENYW8r4RQvPp",
        "colab_type": "text"
      },
      "source": [
        "### **Analiza danych**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bsb25Si_Q-_x",
        "colab_type": "text"
      },
      "source": [
        "Dane są zróżnicowane ze względu na akcent, płeć, oraz wiek. Akcenty, które wchodzą w skład zbioru:\n",
        "* 23% United States English\n",
        "* 9% England English\n",
        "* 4% India and South Asia (India, Pakistan, Sri Lanka)\n",
        "* 3% Australian English\n",
        "* 3% Canadian English\n",
        "* 2% Scottish English\n",
        "* 1% Irish English\n",
        "* 1% Southern African (South Africa, Zimbabwe, Namibia)\n",
        "* 1% New Zealand English\n",
        "\n",
        "Grupy wiekowe są podzielone wg. następujących proporcji:\n",
        "* 22% 19 - 29\n",
        "* 15% 30 - 39\n",
        "* 9% 40 - 49\n",
        "* 5% 50 - 59\n",
        "* 5% < 19\n",
        "* 4% 60 - 69\n",
        "* 1% 70 - 79\n",
        "\n",
        "Podział ze względu na płeć wygląda następująco:\n",
        "* 46% mężczyzna\n",
        "* 13% kobieta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XL-YX92sRRDk",
        "colab_type": "text"
      },
      "source": [
        "## **Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5PGWSh-RV2X",
        "colab_type": "text"
      },
      "source": [
        "### **Opis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0P8fHYyRYb8",
        "colab_type": "text"
      },
      "source": [
        "System został zbudowany przy pomocy następujących narzędzi:\n",
        "* Python - Język programowania wysokiego poziomu ogólnego przeznaczenia.\n",
        "* Numpy - Biblioteka do obliczeń naukowych.\n",
        "* Keras - Biblioteka przeznaczona do sieci neuronowych.\n",
        "* Librosa - Biblioteka przetwarzająca dźwięk.\n",
        "\n",
        "Wbrew powszechnemu przekonaniu o wykorzstaniu rekurencyjnych sieci neuronowych w zadaniach sekwencyjnych (do których zaliczamy właśnie przetwarzanie, czy rozpoznawanie mowy), wykorzystujemy konwolucyjne sieci neuronowe. \n",
        "\n",
        "Jako uzasadnienie naszej decyzji przymujemy przewagę wydajnościową sieci konwolucyjnych. Sieci rekurencyjne przetwarzają informację sekwencyjnie, gdzie dane są zależne od siebie, wykonywane są takie same operacje na każdym jednym elemencie. Sprawia to, że każdy kolejny krok jest uzależniony od poprzedniego, co sprawia, że obliczenia węzłów nie mogą być podzielone na osobne rdzenie, wszystkie muszą być wykonane w odpowiedniej kolejności. Sprawia to, że trening sieci rekurencyjnych jest wolna i nie pozwala na wykorzystanie maximum wydajności sprzętu.\n",
        "\n",
        "Sieci konwolucyjne są pozbawione tych ograniczeń, na dodatek wykorzystując je na zasadzie encodera, możemy z powodzeniem użyć ich w zadaniu typu speech-to-text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnBI6MpnR0lf",
        "colab_type": "text"
      },
      "source": [
        "### **Działanie**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CtnAA4VSJ20",
        "colab_type": "text"
      },
      "source": [
        "Zaczynamy od załadowania potrzebnych nam bibliotek.\n",
        "```\n",
        "import os, sys\n",
        "import librosa as lib\n",
        "import IPython.display as ipd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.io import wavfile #for audio processing\n",
        "import keras\n",
        "from keras.models import load_model\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv1D, Input, MaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras import backend as K\n",
        "K.clear_session()\n",
        "```\n",
        "\n",
        "W kolejnym kroku wczytujemy dane, następnie przetwarzamy je za pomocą biblioteki Librosa na wykres częstotliwości dźwięku.\n",
        "```\n",
        "train_audio_path = \"F:\\\\projekt py\\\\wav\"\n",
        "files = lib.util.find_files(train_audio_path)\n",
        "(samples, sample_rate) = lib.load(train_audio_path+'\\\\common_voice_en_1.wav', sr=16000)\n",
        "amount_of_samples = len(samples)\n",
        "time_array = np.arange(0, float(amount_of_samples), 1) / sample_rate\n",
        "scaled_samples = samples / (2 ** 15)\n",
        "fig = plt.figure(figsize=(14, 8))\n",
        "ax1 = fig.add_subplot(211)\n",
        "ax1.set_title('trenowany dźwięk')\n",
        "ax1.set_xlabel('time')\n",
        "ax1.set_ylabel('Amplitude')\n",
        "ax1.plot(time_array, scaled_samples, linewidth=0.3, alpha=0.7, color='#004bc6')\n",
        "plt.show()\n",
        " ```\n",
        "![wykres](https://doc-14-3o-docs.googleusercontent.com/docs/securesc/lbv1c7hanio529dnbtu5j1g7gtjunqtj/4sq7q7a9lnp18pksmii6b41gke7jds96/1579651200000/00782543097958797517/00782543097958797517/1MAVMPdz5IKk-vUMk-OaQJCpGkD-Wr_uh?e=view&authuser=0&nonce=8jtkpvilg5aos&user=00782543097958797517&hash=0mauh0dffggvobe9p3h8ub24oreutq66)\n",
        "\n",
        "Następnie resamplujemy nasze nagrania na optymalne 8000Hz\n",
        "\n",
        "\n",
        "```\n",
        "samples = librosa.resample(samples, sample_rate, 8000)\n",
        "ipd.Audio(samples, rate=8000)\n",
        "```\n",
        "\n",
        "Budujemy naszą architekturę używając conv1d. Jest to konwolucyjna sieć neuronowa, która działa tylko w jednym wymiarze.\n",
        "\n",
        "![Przybliżona architektura](https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2019/07/model_architecture.jpg.jpg)\n",
        "\n",
        "Implementujemy model przy użyciu biblioteki keras\n",
        "```\n",
        "inputs = Input(shape=(8000,1))\n",
        "\n",
        "conv = Conv1D(8,13, padding='valid', activation='relu', strides=1)(inputs)\n",
        "conv = MaxPooling1D(3)(conv)\n",
        "conv = Dropout(0.3)(conv)\n",
        "\n",
        "\n",
        "conv = Conv1D(16, 11, padding='valid', activation='relu', strides=1)(conv)\n",
        "conv = MaxPooling1D(3)(conv)\n",
        "conv = Dropout(0.3)(conv)\n",
        "\n",
        "conv = Conv1D(32, 9, padding='valid', activation='relu', strides=1)(conv)\n",
        "conv = MaxPooling1D(3)(conv)\n",
        "conv = Dropout(0.3)(conv)\n",
        "\n",
        "conv = Conv1D(64, 7, padding='valid', activation='relu', strides=1)(conv)\n",
        "conv = MaxPooling1D(3)(conv)\n",
        "conv = Dropout(0.3)(conv)\n",
        "\n",
        "conv = Flatten()(conv)\n",
        "\n",
        "conv = Dense(256, activation='relu')(conv)\n",
        "conv = Dropout(0.3)(conv)\n",
        "\n",
        "conv = Dense(128, activation='relu')(conv)\n",
        "conv = Dropout(0.3)(conv)\n",
        "\n",
        "outputs = Dense(len(labels), activation='softmax')(conv)\n",
        "\n",
        "model = Model(inputs, outputs)\n",
        "model.summary()\n",
        "```\n",
        "Definiujemy funckję strat\n",
        "```\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "```\n",
        "Tworzymy wczesne zatrzymanie, oraz checkpoint-y, aby zatrzymać sieć w odpowiednim momencie i zatrzymać najlepszy model.\n",
        "```\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10, min_delta=0.0001) \n",
        "mc = ModelCheckpoint('best_model.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "```\n",
        "Trenujemy model na batchu wielkości 32\n",
        "```\n",
        "history=model.fit(x_tr, y_tr ,epochs=100, callbacks=[es,mc], batch_size=32, validation_data=(x_val,y_val))\n",
        "```\n",
        "Ładujemy najlepszy model\n",
        "```\n",
        "from keras.models import load_model\n",
        "model=load_model('best_model.hdf5')\n",
        "```\n",
        "Definiujemy funkcję, która przewiduje tekst dla danego audio\n",
        "```\n",
        "def predict(audio):\n",
        "    prob=model.predict(audio.reshape(1,8000,1))\n",
        "    index=np.argmax(prob[0])\n",
        "    return classes[index]\n",
        "```\n",
        "Convertujemy pliki audio na tekst\n",
        "```\n",
        "os.listdir('F:/projekt py/test')\n",
        "filepath='F:/projekt py/test/'\n",
        "\n",
        "#reading the voice commands\n",
        "samples, sample_rate = librosa.load(filepath + '/' + 'command_voice_en_493126.wav.wav', sr = 16000)\n",
        "samples = librosa.resample(samples, sample_rate, 8000)\n",
        "ipd.Audio(samples,rate=8000)  \n",
        "\n",
        "predict(samples)\n",
        "```"
      ]
    }
  ]
}